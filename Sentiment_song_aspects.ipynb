{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song based sentiment analysis using Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Samaras Laptop\n",
    "#song_data = pd.read_csv('C:\\\\Users\\sdo\\Studienarbeit\\DIE_DATEN\\datensatz.csv')\n",
    "#song_data = song_data[(song_data['Language'] == 'en')]\n",
    "#song_data.to_csv(\"outData.csv\", index=False)\n",
    "#song_data = pd.read_csv('C:\\\\Users\\sdo\\Studienarbeit\\outData.csv')\n",
    "\n",
    "\n",
    "#Anjas Laptop\n",
    "# song_data = pd.read_csv('../Daten/train.csv')\n",
    "# song_data = song_data[(song_data['Language'] == 'en')]\n",
    "# song_data.to_csv(\"../Daten/outData.csv\", index=False)\n",
    "song_data = pd.read_csv('../Daten/outData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a balanced sample of n songs per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genres = song_data.Genre.nunique()\n",
    "num_topics = num_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Country</td>\n",
       "      <td>I think Im is a world of trouble Talk about a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Country</td>\n",
       "      <td>The crowd rose to their feet 'Round a diamond ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Country</td>\n",
       "      <td>Why, Why'd I let you In Why did I Pretend That...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Country</td>\n",
       "      <td>Every time I go away my baby feels so blue She...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country</td>\n",
       "      <td>VERSE 1 I sit here surrounded by nothin but fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Country</td>\n",
       "      <td>Written by billy burnette. I miss you darling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>I thought we'd always be together In my mind, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Country</td>\n",
       "      <td>Walk through this world with me Go where I go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Country</td>\n",
       "      <td>I bless the day I found you I want to stay aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Country</td>\n",
       "      <td>I don't own a brand new Benz I drive an old pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genre                                             Lyrics\n",
       "0  Country  I think Im is a world of trouble Talk about a ...\n",
       "1  Country  The crowd rose to their feet 'Round a diamond ...\n",
       "2  Country  Why, Why'd I let you In Why did I Pretend That...\n",
       "3  Country  Every time I go away my baby feels so blue She...\n",
       "4  Country  VERSE 1 I sit here surrounded by nothin but fa...\n",
       "5  Country  Written by billy burnette. I miss you darling ...\n",
       "6  Country  I thought we'd always be together In my mind, ...\n",
       "7  Country  Walk through this world with me Go where I go ...\n",
       "8  Country  I bless the day I found you I want to stay aro...\n",
       "9  Country  I don't own a brand new Benz I drive an old pi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data = song_data[[\"Genre\", \"Lyrics\"]]\n",
    "song_data = song_data.groupby('Genre').sample(500).reset_index(drop=True)\n",
    "song_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation/lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data_processed = song_data.copy()\n",
    "song_data_processed['Lyrics'] = song_data_processed['Lyrics'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "song_data_processed['Lyrics'] = song_data_processed['Lyrics'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\anjan\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'), ('is', 'VBZ'), ('very', 'RB'), ('good', 'JJ'), ('food', 'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(\"this is very good food\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was hier gemacht wurde:\n",
    "- Nehmen eines song subsets mit jeweils n songs aus jedem der m genres\n",
    "- Bereinigen der Lyrics mit verschiedenen Preprocessing methoden (Best Practice)\n",
    "- Ziel war die Sentiment Analyse nach verschiedenen Aspekten.\n",
    "\n",
    "### Ergebnis\n",
    "- Sentiment Analyse nach Aspekten stellte sich als schwierig heraus. Die Packages die dafür nötig gewesen wären konnten nicht einfach mit conda runtergeladen werden. Deshalb wurde dieser Ansatz zunächst verworfen\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
